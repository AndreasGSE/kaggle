{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing and pre-analysis\n",
    "This will be a script for doing some of the initial pre-processing and analysis.\n",
    "\n",
    "Script stages:\n",
    "\n",
    "1) Initial stuff and functions for loading in the data and resizing etc.\n",
    "\n",
    "2) Constructing the model\n",
    "\n",
    "3) Initial test to make sure everything works\n",
    "\n",
    "4) Parameter optimisation using SciKit + kerasclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from random import seed\n",
    "\n",
    "# Defining paths\n",
    "train_path = '../../../Desktop/kaggle/cats_dogs/train/' # Locating of dog files\n",
    "test_path = '../../../Desktop/kaggle/cats_dogs/test1/' # Location of cat files\n",
    "pickle_path = '../../../Desktop/kaggle/cats_dogs/' # Location where saving pickles\n",
    "checkpoint_path = './Dropbox/kaggle/cats_dogs/checkpoints' # Location for model_checkpoints\n",
    "\n",
    "# Defining constants\n",
    "NUM_TRAIN = 250\n",
    "NUM_TEST = 100\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "CHANNELS = 3\n",
    "SAMPLE_SIZE = 250 # How many samples we take for the experiments (note will take even of each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will treat the data by their file links - I think this is easier for the time being as it stops having to lug around huge images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../Desktop/kaggle/cats_dogs/train/dog.0.jpg', '../../../Desktop/kaggle/cats_dogs/train/dog.1.jpg', '../../../Desktop/kaggle/cats_dogs/train/dog.10.jpg', '../../../Desktop/kaggle/cats_dogs/train/dog.100.jpg', '../../../Desktop/kaggle/cats_dogs/train/dog.1000.jpg']\n",
      "['../../../Desktop/kaggle/cats_dogs/train/cat.0.jpg', '../../../Desktop/kaggle/cats_dogs/train/cat.1.jpg', '../../../Desktop/kaggle/cats_dogs/train/cat.10.jpg', '../../../Desktop/kaggle/cats_dogs/train/cat.100.jpg', '../../../Desktop/kaggle/cats_dogs/train/cat.1000.jpg']\n",
      "There are 12500 dog files\n",
      "There are 12500 cat files\n"
     ]
    }
   ],
   "source": [
    "# Get the image files\n",
    "train_files = [train_path + file_name for file_name in os.listdir(train_path)]\n",
    "test_files = [test_path + file_name for file_name in os.listdir(test_path)]\n",
    "\n",
    "dog_files = [file_name for file_name in train_files if 'train/dog' in file_name]\n",
    "cat_files = [file_name for file_name in train_files if 'train/cat' in file_name]\n",
    "\n",
    "print(dog_files[0:5])\n",
    "print(cat_files[0:5])\n",
    "print('There are {} dog files'.format(len(dog_files)))\n",
    "print('There are {} cat files'.format(len(cat_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def panel_graph(image_files):\n",
    "    images = [cv2.imread(image_file, cv2.IMREAD_COLOR) for image_file in image_files[0:4]]\n",
    "    images = [image[:,:,::-1] for image in images] # default is BGR for cv2\n",
    "    images = np.reshape(images, (2,2))\n",
    "    _, ax = plt.subplots(2,2)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[i,j].imshow(images[i, j])\n",
    "            ax[i,j].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Displaying some images\n",
    "panel_graph(dog_files)\n",
    "panel_graph(cat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def panel_hist(image_files):\n",
    "    images = [cv2.imread(image_file, cv2.IMREAD_COLOR).mean(axis=2).flatten() for image_file in image_files[0:4]]\n",
    "    images = np.reshape(images, (2,2))\n",
    "    _, ax = plt.subplots(2,2)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[i,j].hist(images[i, j], 255)\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "# Histograms of pixel values\n",
    "panel_hist(dog_files)\n",
    "panel_hist(cat_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once looked at some of the raw data, will transform it and re-graph to see how stuff changes. Transformations to be made are\n",
    "\n",
    "* Resize\n",
    "\n",
    "* Histogram equalisation\n",
    "\n",
    "* Mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "def data_read(image_path):\n",
    "    '''\n",
    "    Function to read in the data and do some of the basic transformations\n",
    "    Note that it will take a single path and transform - everything is for one image\n",
    "    '''\n",
    "    # Load\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    # Histogram\n",
    "    image[:,:,0] = cv2.equalizeHist(image[:,:,0])\n",
    "    image[:,:,1] = cv2.equalizeHist(image[:,:,1])\n",
    "    image[:,:,2] = cv2.equalizeHist(image[:,:,2])\n",
    "    # Resize\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "def data_norm(train, test = None):\n",
    "    '''\n",
    "    Function to get normalise - NOT sure about axes on this one\n",
    "    Note that it will return first the data, then the mean and std\n",
    "    From tests it definitely gets it normalised\n",
    "    '''\n",
    "    # Assuming we have a data frame of all pictures\n",
    "    data_mean = train.mean(axis = 0)\n",
    "    data_std = train.std(axis = 0)\n",
    "    \n",
    "    train -= data_mean\n",
    "    train /= data_std\n",
    "    if test:\n",
    "        test -= data_mean\n",
    "        test /= data_std\n",
    "        return train, test, data_mean, data_std\n",
    "    else:\n",
    "        return train, data_mean, data_std\n",
    "\n",
    "def data_prep(image_files, read = True):\n",
    "    '''\n",
    "    Here we will try to combine all the files into a frame after processing them a bit\n",
    "    '''\n",
    "    num_files = len(image_files)\n",
    "    file_name = pickle_path + 'all_image_data_' + str(num_files) + '.pickle'\n",
    "    if read & os.path.exists(file_name):\n",
    "        print('Loading dataset from file ' + file_name)\n",
    "        with open(file_name, 'rb') as pickle_file:\n",
    "            all_data = pickle.load(pickle_file)\n",
    "        \n",
    "    else:\n",
    "        print('Loading images directly from file')\n",
    "        all_data = np.ndarray((num_files, IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS))\n",
    "\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            # load in the processed image\n",
    "            all_data[i] = data_read(image_file)\n",
    "            if i % 100 == 0:\n",
    "                print('Loaded {} from {} files'.format(i, num_files))\n",
    "        with open(file_name, 'wb') as pickle_file:\n",
    "            print('Writing dataset to file ' + file_name)\n",
    "            pickle.dump(all_data, pickle_file)\n",
    "        \n",
    "    print('Final shape {}'.format(all_data.shape))\n",
    "    return all_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualising the processed images\n",
    "Now will just compare some of the images to see how it works. Not expecting them to necessarily \"look\" better, but to work better with a learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_compare(image_files, start = 0, end = 4):\n",
    "    images_before = [cv2.imread(image_file, cv2.IMREAD_COLOR) for image_file in image_files[start:end]]\n",
    "    images_before = [image[:,:,::-1] for image in images_before]\n",
    "    images_after = [data_read(image_file)[:,:,::-1] for image_file in image_files[start:end]]    \n",
    "    \n",
    "    if start != end:\n",
    "        size = end - start\n",
    "    else:\n",
    "        size = 1\n",
    "        \n",
    "    _, ax = plt.subplots(2, size)\n",
    "    for i in range(size):\n",
    "        ax[0,i].imshow(images_before[i])\n",
    "        ax[1,i].imshow(images_after[i])\n",
    "        ax[0,i].axis('off')\n",
    "        ax[1,i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Displaying some images\n",
    "image_compare(dog_files, start = 5, end = 9)\n",
    "image_compare(cat_files, start = 5, end = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Histograms as here should be more difference - from OpenCV\n",
    "\n",
    "\"Consider an image whose pixel values are confined to some specific range of values only. For eg, brighter image will have all pixels confined to high values. But a good image will have pixels from all regions of the image. So you need to stretch this histogram to either ends (as given in below image, from wikipedia) and that is what Histogram Equalization does (in simple words). This normally improves the contrast of the image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist_compare(image_files, start = 0, end = 4):\n",
    "    images_before = [cv2.imread(image_file, cv2.IMREAD_COLOR).mean(axis=2).flatten() for image_file in image_files[start:end]]\n",
    "    images_after = [data_read(image_file).mean(axis=2).flatten() for image_file in image_files[start:end]]    \n",
    "    \n",
    "    if start != end:\n",
    "        size = end - start\n",
    "    else:\n",
    "        size = 1\n",
    "        \n",
    "    _, ax = plt.subplots(2, size)\n",
    "    for i in range(size):\n",
    "        ax[0,i].hist(images_before[i], 255)\n",
    "        ax[1,i].hist(images_after[i], 255)\n",
    "    plt.show()\n",
    "\n",
    "# Displaying the histograms\n",
    "hist_compare(dog_files)\n",
    "hist_compare(cat_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will look at the whole data set and see how things look after normalisation - note that will only take the sample sized defined to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images directly from file\n",
      "Loaded 0 from 500 files\n",
      "Loaded 100 from 500 files\n",
      "Loaded 200 from 500 files\n",
      "Loaded 300 from 500 files\n",
      "Loaded 400 from 500 files\n",
      "Writing dataset to file ../../../Desktop/kaggle/cats_dogs/all_image_data_500.pickle\n",
      "Final shape (500, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_prep(dog_files[0:SAMPLE_SIZE] + cat_files[0:SAMPLE_SIZE], read = False)\n",
    "data_norm, data_mean, data_std = data_norm(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data_norm.shape)\n",
    "print(data_mean.shape)\n",
    "\n",
    "plt.imshow(data_mean)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(data_norm[251])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the model\n",
    "After preprocessing stuff will start to actually construct the model to be used.\n",
    "\n",
    "The first step will be to just construct a model to be used to test that everything is doing OK and for some sort of a baseline. Then later we will do some parameter optimisation and play around to see how things improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "# Wrapper to get the training set and labels\n",
    "def get_data_labels(index = range(NUM_TRAIN)):\n",
    "    X = data_prep(dog_files[index] + cat_files[index])\n",
    "    y = [1]*len(index) + [0]*len(index)\n",
    "    \n",
    "    X, y = shuffle(X, y, random_state = 0)\n",
    "    return X,y\n",
    "\n",
    "# Defining model\n",
    "def neural_network():\n",
    "    input_shape = (CHANNELS, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    model = Sequential()\n",
    "    # conv layer 32 nodes, 2x2 window, 2 stride with relu activation\n",
    "    model.add(Convolution2D(32, 2, 2, input_shape = input_shape, activation = 'relu'))\n",
    "    # Max pooling with 2,2 pool and 2,2 stride\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid')) # Note that as only one output - no different to softmax\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callback class\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "def train_model():\n",
    "    model = neural_network()\n",
    "    \n",
    "    train, labels = get_data_labels()\n",
    "    train, data_mean, data_std = data_norm(train)\n",
    "    \n",
    "    loss_history = LossHistory()\n",
    "    early_stopping = EarlyStopping(patience=3, verbose=1)\n",
    "    checkpoints = ModelCheckpoint(checkpoint_path, verbose=1, period = 5)\n",
    "    \n",
    "    model.fit(train, labels, batch_size = 30, nb_epoch = 10, validation_split = 0.2,\n",
    "             shuffle = True, callbacks = [loss_history, early_stopping, checkpoints])\n",
    "    return model, history, data_mean, data_std # return just the model so that we don't have to give it test data and messy stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once have all of the training details out of the way, will call everything and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test(train_mean, train_std, index = range(NUM_TRAIN + 1, NUM_TRAIN + NUM_TEST)):\n",
    "    test_X, test_y = get_data_labels(index)\n",
    "    test_X -= data_mean\n",
    "    test_X /= data_std\n",
    "    \n",
    "    return test_X, test_y\n",
    "\n",
    "def run_training():\n",
    "    model, history, train_mean, train_std = train_model()\n",
    "    print('finished model training')\n",
    "    \n",
    "    test_X, test_y = get_test(train_mean, train_std)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    prob_thresholds = np.arange(0, 1.1, 0.1)\n",
    "    \n",
    "    for thresh in prob_thresholds:\n",
    "        y_hat = [1 if prediction > thresh else 0 for prediction in predictions]\n",
    "        print('Accuracy at {} for a random test_set is {}'.format(thresh, np.mean([y_h == y for y_h, y in zip(y_hat, test_y)]))) \n",
    "    \n",
    "    # Graphing the loss\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.plot(history.loss, 'blue', label='Training Loss')\n",
    "    plt.plot(history.val_loss, 'green', label='Validation Loss')\n",
    "    plt.xticks(range(0,10)[0::2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
